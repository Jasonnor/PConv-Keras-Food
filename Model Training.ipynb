{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Training\n",
    "Having implemented and tested all the components of the final networks in steps 1-3, we are now ready to train the network on a large dataset (ImageNet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import backend as K\n",
    "\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from libs.pconv_model import PConvUnet\n",
    "from libs.util import random_mask\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating train & test data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import piexif\n",
    "import imghdr\n",
    "def split_dataset_into_test_and_train_sets(all_data_dir, training_data_dir, testing_data_dir, testing_data_pct):\n",
    "    # Recreate testing and training directories\n",
    "    if testing_data_dir.count('/') > 1:\n",
    "        shutil.rmtree(testing_data_dir, ignore_errors=False)\n",
    "        os.makedirs(testing_data_dir)\n",
    "        print(\"Successfully cleaned directory \" + testing_data_dir)\n",
    "    else:\n",
    "        print(\"Refusing to delete testing data directory \" + testing_data_dir + \" as we prevent you from doing stupid things!\")\n",
    "\n",
    "    if training_data_dir.count('/') > 1:\n",
    "        shutil.rmtree(training_data_dir, ignore_errors=False)\n",
    "        os.makedirs(training_data_dir)\n",
    "        print(\"Successfully cleaned directory \" + training_data_dir)\n",
    "    else:\n",
    "        print(\"Refusing to delete testing data directory \" + training_data_dir + \" as we prevent you from doing stupid things!\")\n",
    "\n",
    "    num_training_files = 0\n",
    "    num_testing_files = 0\n",
    "\n",
    "    for subdir, dirs, files in os.walk(all_data_dir):\n",
    "        category_name = os.path.basename(subdir)\n",
    "\n",
    "        # Don't create a subdirectory for the root directory\n",
    "        print(category_name + \" vs \" + os.path.basename(all_data_dir))\n",
    "        if category_name == os.path.basename(all_data_dir):\n",
    "            continue\n",
    "\n",
    "        training_data_category_dir = training_data_dir + '/' + category_name\n",
    "        testing_data_category_dir = testing_data_dir + '/' + category_name\n",
    "\n",
    "        if not os.path.exists(training_data_category_dir):\n",
    "            os.mkdir(training_data_category_dir)\n",
    "\n",
    "        if not os.path.exists(testing_data_category_dir):\n",
    "            os.mkdir(testing_data_category_dir)\n",
    "\n",
    "        for file in files:\n",
    "            input_file = os.path.join(subdir, file)\n",
    "            \n",
    "            # Remove EXIF data\n",
    "            if(imghdr.what(input_file) == 'jpeg'):\n",
    "                piexif.remove(input_file)\n",
    "            \n",
    "            if np.random.rand(1) < testing_data_pct:\n",
    "                shutil.copy(input_file, testing_data_dir + '/' + category_name + '/' + file)\n",
    "                num_testing_files += 1\n",
    "            else:\n",
    "                shutil.copy(input_file, training_data_dir + '/' + category_name + '/' + file)\n",
    "                num_training_files += 1\n",
    "\n",
    "    print(\"Processed \" + str(num_training_files) + \" training files.\")\n",
    "    print(\"Processed \" + str(num_testing_files) + \" testing files.\")\n",
    "\n",
    "split_dataset_into_test_and_train_sets('/data/hackathon/dataset/ultra-food20/', '/data/hackathon/dataset/ultra-train80/', '/data/hackathon/dataset/ultra-temp20/', 0.2)\n",
    "\n",
    "split_dataset_into_test_and_train_sets('/data/hackathon/dataset/ultra-temp20/', '/data/hackathon/dataset/ultra-val10/', '/data/hackathon/dataset/ultra-test10/', 0.5)\n",
    "\n",
    "#data_generator = ImageDataGenerator(rescale=1./255, validation_split=0.33)\n",
    "\n",
    "#train_generator = data_generator.flow_from_directory(TRAINING_DIR, target_size=(IMAGE_SIZE, IMAGE_SIZE), shuffle=True, seed=13,\n",
    "#                                                     class_mode='categorical', batch_size=BATCH_SIZE, subset=\"training\")\n",
    "\n",
    "#validation_generator = data_generator.flow_from_directory(TRAINING_DIR, target_size=(IMAGE_SIZE, IMAGE_SIZE), shuffle=True, seed=13,\n",
    "#                                                     class_mode='categorical', batch_size=BATCH_SIZE, subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTINGS\n",
    "\n",
    "TRAIN_DIR = '/data/hackathon/dataset/subdataset/ultra-salad-train'\n",
    "TEST_DIR = '/data/hackathon/dataset/subdataset/ultra-salad-test'\n",
    "VAL_DIR = '/data/hackathon/dataset/subdataset/ultra-salad-val'\n",
    "\n",
    "TRAIN_DIR = '/data/hackathon/dataset/ultra-train80'\n",
    "TEST_DIR = '/data/hackathon/dataset/ultra-test10'\n",
    "VAL_DIR = '/data/hackathon/dataset/ultra-val10'\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "class DataGenerator(ImageDataGenerator):\n",
    "    def flow_from_directory(self, directory, *args, **kwargs):\n",
    "        generator = super().flow_from_directory(directory, class_mode=None, *args, **kwargs)\n",
    "        while True:\n",
    "            \n",
    "            # Get augmentend image samples\n",
    "            ori = next(generator)\n",
    "\n",
    "            # Get masks for each image sample\n",
    "            mask = np.stack([random_mask(ori.shape[1], ori.shape[2]) for _ in range(ori.shape[0])], axis=0)\n",
    "\n",
    "            # Apply masks to all image sample\n",
    "            masked = deepcopy(ori)\n",
    "            masked[mask==0] = 1\n",
    "\n",
    "            # Yield ([ori, masl],  ori) training batches\n",
    "            # print(masked.shape, ori.shape)\n",
    "            gc.collect()\n",
    "            yield [masked, mask], ori\n",
    "            \n",
    "# Create training generator\n",
    "train_datagen = DataGenerator(  \n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR, target_size=(256, 256), batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Create validation generator\n",
    "val_datagen = DataGenerator(rescale=1./255)\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    VAL_DIR, target_size=(256, 256), batch_size=BATCH_SIZE, seed=1\n",
    ")\n",
    "\n",
    "# Create testing generator\n",
    "test_datagen = DataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR, target_size=(256, 256), batch_size=BATCH_SIZE, seed=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick out an example\n",
    "test_data = next(test_generator)\n",
    "(masked, mask), ori = test_data\n",
    "\n",
    "# Show side by side\n",
    "for i in range(len(ori)):\n",
    "    _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "    axes[0].imshow(masked[i,:,:,:])\n",
    "    axes[1].imshow(mask[i,:,:,:] * 1.)\n",
    "    axes[2].imshow(ori[i,:,:,:])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_callback(model):\n",
    "    \"\"\"Called at the end of each epoch, displaying our previous test images,\n",
    "    as well as their masked predictions and saving them to disk\"\"\"\n",
    "    \n",
    "    # Get samples & Display them        \n",
    "    pred_img = model.predict([masked, mask])\n",
    "    pred_time = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "    # Clear current output and display test images\n",
    "    for i in range(len(ori)):\n",
    "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "        axes[0].imshow(masked[i,:,:,:])\n",
    "        axes[1].imshow(pred_img[i,:,:,:] * 1.)\n",
    "        axes[2].imshow(ori[i,:,:,:])\n",
    "        axes[0].set_title('Masked Image')\n",
    "        axes[1].set_title('Predicted Image')\n",
    "        axes[2].set_title('Original Image')\n",
    "                \n",
    "        plt.savefig('/data/hackathon/PConv-Keras/data/test_samples/img_{}.png'.format(pred_time))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1 - with batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "pretrained = '/data/hackathon/PConv-Keras/data/logs_salad/57_weights_2018-08-16-09-41-48.h5'\n",
    "pretrained = '/data/hackathon/PConv-Keras/data/logs/45_weights_2018-08-16-13-03-38.h5'\n",
    "weight_path = '/data/hackathon/PConv-Keras/data/logs_salad/'\n",
    "weight_path = '/data/hackathon/PConv-Keras/data/logs/'\n",
    "\n",
    "model = PConvUnet(weight_filepath=weight_path)\n",
    "model.load(pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/46\n",
      "Found 4310 images belonging to 20 classes.\n",
      "Found 34389 images belonging to 20 classes.\n",
      "2059/2149 [===========================>..] - ETA: 42s - loss: 195792.9492"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jason/.local/lib/python3.6/site-packages/PIL/Image.py:931: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  'to RGBA images')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 1048s 488ms/step - loss: 195634.0420 - val_loss: 230168.2180\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'masked' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-62d7add2e338>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mplot_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplot_callback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     callbacks=[\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'initial_training'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     ]\n\u001b[1;32m     12\u001b[0m )\n",
      "\u001b[0;32m/data/hackathon/PConv-Keras/libs/pconv_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, generator, epochs, plot_callback, *args, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;31m# After each epoch predict on test images & show them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mplot_callback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                 \u001b[0mplot_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;31m# Save logfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-0be446251681>\u001b[0m in \u001b[0;36mplot_callback\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Get samples & Display them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpred_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmasked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mpred_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y-%m-%d-%H-%M-%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'masked' is not defined"
     ]
    }
   ],
   "source": [
    "# Run training for certain amount of epochs\n",
    "model.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch=2149,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=100,\n",
    "    epochs=30,\n",
    "    plot_callback=plot_callback,\n",
    "    callbacks=[\n",
    "        TensorBoard(log_dir=weight_path + 'initial_training', write_graph=False)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2 - without batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights from previous run\n",
    "model = PConvUnet(weight_filepath=weight_path)\n",
    "model.load(\n",
    "    pretrained,\n",
    "    train_bn=False,\n",
    "    lr=0.00005\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run training for certain amount of epochs\n",
    "model.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch=10000,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=100,\n",
    "    epochs=20,        \n",
    "    workers=3,\n",
    "    plot_callback=plot_callback,\n",
    "    callbacks=[\n",
    "        TensorBoard(log_dir=weight_path + 'initial_training', write_graph=False)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Phase 3 - Generating samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights from previous run\n",
    "model = PConvUnet(weight_filepath=weight_path)\n",
    "model.load(\n",
    "    pretrained,\n",
    "    train_bn=False,\n",
    "    lr=0.00005\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "for (masked, mask), ori in tqdm(test_generator):\n",
    "    # Run predictions for this batch of images\n",
    "    pred_img = model.predict([masked, mask])\n",
    "    pred_time = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "    \n",
    "    # Clear current output and display test images\n",
    "    for i in range(len(ori)):\n",
    "        _, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        axes[0].imshow(masked[i,:,:,:])\n",
    "        axes[1].imshow(pred_img[i,:,:,:] * 1.)\n",
    "        axes[0].set_title('Masked Image')\n",
    "        axes[1].set_title('Predicted Image')\n",
    "        axes[0].xaxis.set_major_formatter(NullFormatter())\n",
    "        axes[0].yaxis.set_major_formatter(NullFormatter())\n",
    "        axes[1].xaxis.set_major_formatter(NullFormatter())\n",
    "        axes[1].yaxis.set_major_formatter(NullFormatter())\n",
    "        \n",
    "        plt.show()\n",
    "        #plt.savefig('/data/hackathon/PConv-Keras/data/test_samples/img_{}_{}.png'.format(i, pred_time))\n",
    "        #plt.close()\n",
    "        n += 1\n",
    "    # Only create predictions for about 100 images\n",
    "    if n > 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "import warnings\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import attr\n",
    "import skimage.io as ski_io\n",
    "import skimage.color as ski_color\n",
    "import skimage.morphology as ski_morph\n",
    "\n",
    "@attr.s\n",
    "class FoodQuiz:\n",
    "    question_id = attr.ib()\n",
    "    raw_image = attr.ib()\n",
    "    bbox = attr.ib()\n",
    "    description = attr.ib()\n",
    "\n",
    "\n",
    "# 從 PIXNET 拿到比賽題目\n",
    "def get_image(question_id, img_header=True):\n",
    "    endpoint = 'http://pixnethackathon2018-competition.events.pixnet.net/api/question'\n",
    "    payload = dict(question_id=question_id, img_header=img_header)\n",
    "    print('Step 1: 從 PIXNET 拿比賽題目\\n')\n",
    "    response = requests.get(endpoint, params=payload)\n",
    "\n",
    "    try:\n",
    "        data = response.json()['data']\n",
    "        question_id = data['question_id']\n",
    "        description = data['desc']\n",
    "        bbox = data['bounding_area']\n",
    "        encoded_image = data['image']\n",
    "        raw_image = ski_io.imread(\n",
    "            BytesIO(base64.b64decode(encoded_image[encoded_image.find(',')+1:]))\n",
    "        )\n",
    "\n",
    "        header = encoded_image[:encoded_image.find(',')]\n",
    "        if 'bmp' not in header:\n",
    "            raise ValueError('Image should be BMP format')\n",
    "\n",
    "        print('題號：', question_id)\n",
    "        print('文字描述：', description)\n",
    "        print('Bounding Box:', bbox)\n",
    "        print('影像物件：', type(raw_image), raw_image.dtype, ', 影像大小：', raw_image.shape)\n",
    "\n",
    "        quiz = FoodQuiz(question_id, raw_image, bbox, description)\n",
    "\n",
    "    except Exception as err:\n",
    "        # Catch exceptions here...\n",
    "        print(data)\n",
    "        raise err\n",
    "\n",
    "    print('=====================')\n",
    "\n",
    "    return quiz\n",
    "\n",
    "# 上傳答案到 PIXNET\n",
    "def submit_image(image, question_id):\n",
    "    print('Step 3: 上傳答案到 PIXNET\\n')\n",
    "\n",
    "    endpoint = 'http://pixnethackathon2018-competition.events.pixnet.net/api/answer'\n",
    "\n",
    "    #key = os.environ.get('PIXNET_FOODAI_KEY')\n",
    "    key = 'nKGAB53gSyNsCBXV'\n",
    "\n",
    "    # Assign image format\n",
    "    image_format = 'jpeg'\n",
    "    with BytesIO() as f:\n",
    "        ski_io.imsave(f, image, format_str=image_format)\n",
    "        f.seek(0)\n",
    "        data = f.read()\n",
    "        encoded_image = base64.b64encode(data)\n",
    "    image_b64string = 'data:image/{};base64,'.format(image_format) + encoded_image.decode('utf-8')\n",
    "\n",
    "    payload = dict(question_id=question_id,\n",
    "                   key=key,\n",
    "                   image=image_b64string)\n",
    "    response = requests.post(endpoint, json=payload)\n",
    "    try:\n",
    "        rdata = response.json()\n",
    "        if response.status_code == 200 and not rdata['error']:\n",
    "            print('上傳成功')\n",
    "        print('題號：', question_id)\n",
    "        print('回答截止時間：', rdata['data']['expired_at'])\n",
    "        print('所剩答題次數：', rdata['data']['remain_quota'])\n",
    "\n",
    "    except Exception as err:\n",
    "        print(rdata)\n",
    "        raise err\n",
    "    print('=====================')\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(\n",
    "    description='''\n",
    "    PIXNET HACKATHON 競賽平台測試 0731 版.\n",
    "    測試流程： `get_image` --> `inpainting` --> `submit_image`\n",
    "    1. `get_image`: 取得測試題目，必須指定題目編號。\n",
    "    2. `inpainting`: 參賽者的補圖邏輯實作在這一個 stage\n",
    "    3. `submit_image`: 將補好的圖片與題號，提交回server，透過 PIXNET 核發的 API token 識別身份，故 token 請妥善保存。\n",
    "    執行範例1：\n",
    "        $ bash -c \"export PIXNET_FOODAI_KEY=<YOUR-API-TOKEN>; python api_test_0731.py --qid 1\"\n",
    "    執行範例2:\n",
    "        a. 將 API-TOKEN 如以下形式寫入某檔案，例如 .secrets.env 並存檔。\n",
    "            export PIXNET_FOODAI_KEY=<YOUR-API-TOKEN>\n",
    "        b. 執行:\n",
    "        $ bash -c \"source .secrets.env; python api_test_0731.py --qid 1\"\n",
    "    API 文件：https://github.com/pixnet/2018-pixnet-hackathon/blob/master/opendata/food.competition.api.md\n",
    "    競賽平台位置：http://pixnethackathon2018-competition.events.pixnet.net/''',\n",
    "    formatter_class=argparse.RawTextHelpFormatter\n",
    ")\n",
    "parser.add_argument('--qid', metavar='qid', nargs='?', type=int, default=1, help='題目編號(int)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用你的模型，補全影像\n",
    "def inpainting(quiz, debug=True):\n",
    "\n",
    "    print('Step 2: 使用你的模型，補全影像\\n')\n",
    "    print('...')\n",
    "\n",
    "    # Demo: mean-color inpainting\n",
    "    raw_image = quiz.raw_image.copy()\n",
    "    bbox = quiz.bbox\n",
    "    mean_color = quiz.raw_image.mean(axis=(0, 1))  # shape: (3,)\n",
    "    \n",
    "    raw_roi = raw_image[bbox['y']:bbox['y']+bbox['h'], bbox['x']:bbox['x']+bbox['w'], :]\n",
    "    mask = np.zeros(raw_image.shape[:2])\n",
    "    mask_roi = mask[bbox['y']:bbox['y']+bbox['h'], bbox['x']:bbox['x']+bbox['w']]\n",
    "\n",
    "    to_filling = (raw_roi[:, :, 1] == 255) & (raw_roi[:, :, 0] == 0) & (raw_roi[:, :, 2] == 0)\n",
    "    mask_roi[to_filling] = 1\n",
    "    \n",
    "    mask = ski_morph.dilation(mask, ski_morph.square(7))\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    \n",
    "    mask = np.repeat(mask, 3, axis=2)\n",
    "    mask = 1 - mask\n",
    "    #ski_io.imshow(mask)\n",
    "    \n",
    "    masked = deepcopy(raw_image)\n",
    "    masked[mask == 0] = 255\n",
    "    masked = [x / 255.0 for x in masked]\n",
    "    \n",
    "    mask_p = np.expand_dims(mask, axis=0)\n",
    "    masked_p = np.expand_dims(masked, axis=0)\n",
    "    \n",
    "    gen_time = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "    gen_image = model.predict([masked_p, mask_p])\n",
    "    \n",
    "\n",
    "    if debug:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore', category=UserWarning)\n",
    "            _, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "            axes[0].imshow(masked)\n",
    "            axes[1].imshow(gen_image[0,:,:,:])\n",
    "            axes[0].set_title('Masked Image')\n",
    "            axes[1].set_title('Predicted Image')\n",
    "            axes[0].xaxis.set_major_formatter(NullFormatter())\n",
    "            axes[0].yaxis.set_major_formatter(NullFormatter())\n",
    "            axes[1].xaxis.set_major_formatter(NullFormatter())\n",
    "            axes[1].yaxis.set_major_formatter(NullFormatter())\n",
    "            plt.savefig('/data/hackathon/PConv-Keras/data/output/img_{}.png'.format(gen_time))\n",
    "            plt.show()\n",
    "\n",
    "    print('=====================')\n",
    "\n",
    "    return gen_image[0,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights from previous run\n",
    "\n",
    "pretrained = '/data/hackathon/PConv-Keras/data/logs_salad/36_weights_2018-08-15-22-57-07.h5'\n",
    "pretrained = '/data/hackathon/PConv-Keras/data/logs_sushi/35_weights_2018-08-15-18-46-27.h5'\n",
    "pretrained = '/data/hackathon/PConv-Keras/data/logs_sashimi/35_weights_2018-08-15-18-46-27.h5'\n",
    "pretrained = '/data/hackathon/PConv-Keras/data/logs/35_weights_2018-08-15-18-46-27.h5'\n",
    "\n",
    "model = PConvUnet(weight_filepath=weight_path)\n",
    "model.load(\n",
    "    pretrained,\n",
    "    train_bn=False,\n",
    "    lr=0.00005\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#args = parser.parse_args()\n",
    "quiz = get_image(10)\n",
    "gen_image = inpainting(quiz)\n",
    "submit_image(gen_image, quiz.question_id)\n",
    "print('Done... Waiting for next round.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
